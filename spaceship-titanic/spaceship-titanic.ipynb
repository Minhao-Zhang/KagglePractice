{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X = train_data.drop([\"Transported\"], axis=1)\n",
    "y = train_data[\"Transported\"]\n",
    "X_test = test_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP   \n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False  \\\n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy  \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines  \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent  \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent  \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group people by Transported \n",
    "transported = train_data[train_data['Transported']==True]\n",
    "not_transported = train_data[train_data['Transported']==False]\n",
    "\n",
    "# print(transported.describe())\n",
    "# print(not_transported.describe())\n",
    "X.head()\n",
    "\n",
    "# # find the row number if any of the columns are null\n",
    "# rows = np.where(pd.isnull(X))\n",
    "# X.iloc[rows]\n",
    "\n",
    "# # find all column names that contain null values\n",
    "# null_col_names = X.columns[X.isnull().any()]\n",
    "# null_col_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer1 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_X = pd.DataFrame(imputer1.fit_transform(X), columns=X.columns)\n",
    "imp_X_test = pd.DataFrame(imputer1.transform(test_data), columns=test_data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Cabin column into Deck, Num, and Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the column \"Cabin\" into three columns \"Deck\", \"Num\", \"Side\"\n",
    "cabin = imp_X[\"Cabin\"].str.split(\"/\", n = 2, expand = True)\n",
    "# rename the columns\n",
    "cabin = cabin.rename(columns={0: \"Deck\", 1: \"Num\", 2: \"Side\"})\n",
    "# add the new columns to the dataframe\n",
    "split_X = pd.concat([imp_X, cabin], axis=1)\n",
    "split_X.drop([\"Cabin\"], axis=1, inplace=True)\n",
    "split_X\n",
    "\n",
    "cabin_test = imp_X_test[\"Cabin\"].str.split(\"/\", n = 2, expand = True)\n",
    "cabin_test = cabin_test.rename(columns={0: \"Deck\", 1: \"Num\", 2: \"Side\"})\n",
    "split_X_test = pd.concat([imp_X_test, cabin_test], axis=1)\n",
    "split_X_test.drop([\"Cabin\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Deck\", \"Num\", \"Side\"]\n",
    "features = [\"HomePlanet\", \"CryoSleep\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Deck\", \"Num\", \"Side\"]\n",
    "\n",
    "X_lg = split_X[features]\n",
    "y_lg = y\n",
    "X_lg_test = split_X_test[features]\n",
    "\n",
    "X_lg.head()\n",
    "\n",
    "# categorical_features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]\n",
    "categorical_features = [\"HomePlanet\", \"CryoSleep\", \"VIP\", \"Deck\", \"Side\"]\n",
    "\n",
    "# one hot encode all the categorical features\n",
    "one_hot = OneHotEncoder()\n",
    "one_hot_X = one_hot.fit_transform(X_lg[categorical_features])\n",
    "one_hot_X_test = one_hot.transform(X_lg_test[categorical_features])\n",
    "\n",
    "# add the encoded variable back to the dataframe\n",
    "X_lg = X_lg.join(pd.DataFrame(one_hot_X.toarray(), columns=one_hot.get_feature_names_out()))\n",
    "X_lg_test = X_lg_test.join(pd.DataFrame(one_hot_X_test.toarray(), columns=one_hot.get_feature_names_out()))\n",
    "\n",
    "X_lg.drop(categorical_features, axis=1, inplace=True)\n",
    "X_lg_test.drop(categorical_features, axis=1, inplace=True)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_lg, y_lg)\n",
    "predictions = model.predict(X_lg_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Transported': predictions})\n",
    "output.to_csv('rfc1_submission.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation to select the best imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# split the cabin column into three sub columns\n",
    "cabin = X[\"Cabin\"].str.split(\"/\", n = 2, expand = True)\n",
    "# rename the columns\n",
    "cabin = cabin.rename(columns={0: \"Deck\", 1: \"Num\", 2: \"Side\"})\n",
    "# add the new columns to the dataframe\n",
    "split_X = pd.concat([X, cabin], axis=1)\n",
    "split_X.drop([\"Cabin\"], axis=1, inplace=True)\n",
    "\n",
    "cabin_test = X_test[\"Cabin\"].str.split(\"/\", n = 2, expand = True)\n",
    "cabin_test = cabin_test.rename(columns={0: \"Deck\", 1: \"Num\", 2: \"Side\"})\n",
    "split_X_test = pd.concat([X_test, cabin_test], axis=1)\n",
    "split_X_test.drop([\"Cabin\"], axis=1, inplace=True)\n",
    "\n",
    "# features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Deck\", \"Num\", \"Side\"]\n",
    "features = [\"HomePlanet\", \"CryoSleep\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Deck\", \"Num\", \"Side\"]\n",
    "\n",
    "X_lg = split_X[features]\n",
    "y_lg = y\n",
    "X_lg_test = split_X_test[features]\n",
    "\n",
    "\n",
    "# categorical_features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]\n",
    "categorical_features = [\"HomePlanet\", \"CryoSleep\", \"VIP\", \"Deck\", \"Side\"]\n",
    "numerical_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Num\"]\n",
    "\n",
    "# one hot encode all the categorical features\n",
    "one_hot = OneHotEncoder()\n",
    "one_hot_X = one_hot.fit_transform(X_lg[categorical_features])\n",
    "one_hot_X_test = one_hot.transform(X_lg_test[categorical_features])\n",
    "\n",
    "# add the encoded variable back to the dataframe\n",
    "X_lg = X_lg.join(pd.DataFrame(one_hot_X.toarray(), columns=one_hot.get_feature_names_out()))\n",
    "X_lg_test = X_lg_test.join(pd.DataFrame(one_hot_X_test.toarray(), columns=one_hot.get_feature_names_out()))\n",
    "\n",
    "X_lg.drop(categorical_features, axis=1, inplace=True)\n",
    "X_lg_test.drop(categorical_features, axis=1, inplace=True)\n",
    "\n",
    "# scale the numerical features\n",
    "# scaler = StandardScaler()\n",
    "# X_lg = pd.DataFrame(scaler.fit_transform(X_lg), columns=X_lg.columns)\n",
    "# X_lg_test = pd.DataFrame(scaler.transform(X_lg_test), columns=X_lg_test.columns)\n",
    "\n",
    "# add in missing values\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "imputer = KNNImputer(n_neighbors=20)\n",
    "X_lg = pd.DataFrame(imputer.fit_transform(X_lg), columns=X_lg.columns)\n",
    "X_lg_test = pd.DataFrame(imputer.transform(X_lg_test), columns=X_lg_test.columns)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# score = cross_val_score(model, X_lg, y_lg, cv=5)\n",
    "# print(score.mean())\n",
    "\n",
    "model.fit(X_lg, y_lg)\n",
    "predictions = model.predict(X_lg_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Transported': predictions})\n",
    "output.to_csv('lg_submission_KNN.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
